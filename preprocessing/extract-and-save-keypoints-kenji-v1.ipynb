{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [
                {
                    "file_id": "1oInUJxh7vG7piq9t6Dj2HEVGDb5Mcj23",
                    "timestamp": 1732755945773
                }
            ]
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "language_info": {
            "name": "python"
        }
    },
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# Notebook Explanation and Important Link\n",
                "This notebook follows the same data format as Aditya's, so you should be able to use the data by simply changing the directory or link, if necessary. <br>\n",
                "\n",
                "There are 3 main changes that have been made:\n",
                "1.   Instead of using B's videos (which was highly optimized for CNN), Wiame's videos are used. It maintains the original resolution but has standardized frames (113 frames). If the duration still seems too long, you can simply select 1 frame every 2 or 3 frames to reduce it.\n",
                "2.   Face Landmark Removal. Previously, in addition to Pose (33 landmarks) and Hands (21x2 landmarks), the Face model with 468 landmarks was included. However, due to the imbalance in the number of landmarks and the limited contribution of facial data to sign language recognition, it was removed.\n",
                "3.   When the pose or hand is not detected, instead of using a zero array as a padding, the previous detected coordinates are used to maintain continuity.\n",
                "\n",
                "Data Format<br>\n",
                "The output numpy array has the shape (113, 75, 3):<br>\n",
                "113 = Frame count <br>\n",
                "75 = Key points (0-32 pose, 33-53 left hand, 54-74 right hand). You can select specific hand indices if needed.<br>\n",
                "3 = Coordinates (x,y,z).\n",
                "\n",
                "Link:\n",
                "1.   [All data for and from this notebook, drive](https://drive.google.com/drive/folders/1rTRZxMkvAyf805AuPoVvrfw8KnB3Ttod?usp=share_link)\n",
                "2.   [Aditya original notebook, slack post](https://omdenaindones-9mu9399.slack.com/archives/C07MH4C0YLF/p1732443924936359)\n",
                "3.   [Wiame processed videos, slack post](https://omdenaindones-9mu9399.slack.com/archives/C07N05MQNCC/p1732105984337299)\n",
                "\n",
                "\n"
            ],
            "metadata": {
                "id": "mZnu4YU__0Xu"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Future Improvement\n",
                "\n",
                "1.   **Landmark-Level Augmentation.** Similar to video augmentation, but applied only to the coordinates. This includes mirroring, rotation, and adding noise.\n",
                "2.   **Model Result Comparison(Zero vs. Non-Zero).** A reference for future extraction, comparing results when using zero-filled coordinates versus using previously detected coordinates.\n",
                "3.   **Specific Hand and Pose Detection (vs. Holistic).** Focusing on specific hands and poses rather than holistic detection could allow for more flexible parameters, improving extraction performance and reducing landmark extraction duration.\n",
                "4.   **Confidence Parameter Adjustment.** Instead of using the default confidence threshold of 5, adjust it depending on the hand detection frequency. Lower it if hands are often not detected, or increase it for more precise results.\n",
                "5. **GPU Version?**\n",
                "\n",
                "\n"
            ],
            "metadata": {
                "id": "4TyJEm-eBaD-"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Install and Import Dependencies"
            ],
            "metadata": {
                "id": "APuxWetJyNYy"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "!pip install -q mediapipe"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "taep2Ct_yJYf",
                "executionInfo": {
                    "status": "ok",
                    "timestamp": 1733487093799,
                    "user_tz": -420,
                    "elapsed": 19819,
                    "user": {
                        "displayName": "Kenji Surya Utama",
                        "userId": "07896803662774016361"
                    }
                },
                "outputId": "5d9fa328-983f-4a3f-b9db-945d05ceda24"
            },
            "execution_count": 1,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m36.1/36.1 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25h"
                    ]
                }
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {
                "id": "n5vuIqvyxf6C",
                "executionInfo": {
                    "status": "ok",
                    "timestamp": 1733487108810,
                    "user_tz": -420,
                    "elapsed": 10980,
                    "user": {
                        "displayName": "Kenji Surya Utama",
                        "userId": "07896803662774016361"
                    }
                }
            },
            "outputs": [],
            "source": [
                "import os\n",
                "import cv2\n",
                "import numpy as np\n",
                "import mediapipe as mp"
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "from google.colab import drive\n",
                "drive.mount('/content/drive')"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "hleMntX5ylbd",
                "executionInfo": {
                    "status": "ok",
                    "timestamp": 1733487127648,
                    "user_tz": -420,
                    "elapsed": 17459,
                    "user": {
                        "displayName": "Kenji Surya Utama",
                        "userId": "07896803662774016361"
                    }
                },
                "outputId": "33740e98-ed4e-4112-e72a-762c7534d2ad"
            },
            "execution_count": 3,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Mounted at /content/drive\n"
                    ]
                }
            ]
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Extract and Save Keypoints"
            ],
            "metadata": {
                "id": "5ttq5zr5yX91"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Non-Zero Extraction\n",
                "\n",
                "When the pose or hand is not detected, instead of using [0, 0, 0] to fill the coordinates, the previously detected coordinates are used. This way, the continuity of movement is preserved."
            ],
            "metadata": {
                "id": "QucGgt5ps2Dz"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Initialize Mediapipe Holistic\n",
                "mp_holistic = mp.solutions.holistic\n",
                "holistic = mp_holistic.Holistic(static_image_mode=False,\n",
                "                                min_detection_confidence=0.3,\n",
                "                                min_tracking_confidence=0.3)\n",
                "\n",
                "def extract_keypoints(video_path):\n",
                "\n",
                "    prev_left_keypoints = np.zeros((21, 3))\n",
                "    prev_right_keypoints = np.zeros((21, 3))\n",
                "    prev_pose_keypoints = np.zeros((33, 3))\n",
                "\n",
                "    cap = cv2.VideoCapture(video_path)\n",
                "    keypoints_sequence = []\n",
                "\n",
                "    while cap.isOpened():\n",
                "        ret, frame = cap.read()\n",
                "        if not ret:\n",
                "            break\n",
                "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
                "        results = holistic.process(frame_rgb)\n",
                "\n",
                "        # Extract pose landmarks\n",
                "        if results.pose_landmarks:\n",
                "            pose_keypoints = np.array([[lm.x, lm.y, lm.z] for lm in results.pose_landmarks.landmark])\n",
                "            prev_pose_keypoints = pose_keypoints\n",
                "        else:\n",
                "            pose_keypoints = prev_pose_keypoints  # 33 pose landmarks\n",
                "\n",
                "        # Extract hand landmarks\n",
                "        if results.left_hand_landmarks:\n",
                "            left_hand_keypoints = np.array([[lm.x, lm.y, lm.z] for lm in results.left_hand_landmarks.landmark])\n",
                "            prev_left_keypoints = left_hand_keypoints\n",
                "        else:\n",
                "            left_hand_keypoints = prev_left_keypoints  # 21 hand landmarks for left hand\n",
                "\n",
                "        if results.right_hand_landmarks:\n",
                "            right_hand_keypoints = np.array([[lm.x, lm.y, lm.z] for lm in results.right_hand_landmarks.landmark])\n",
                "            prev_right_keypoints = right_hand_keypoints\n",
                "        else:\n",
                "            right_hand_keypoints = prev_right_keypoints  # 21 hand landmarks for right hand'\n",
                "\n",
                "        # Concatenate all keypoints into a single vector\n",
                "        keypoints = np.concatenate([pose_keypoints, left_hand_keypoints, right_hand_keypoints])\n",
                "        keypoints_sequence.append(keypoints)\n",
                "\n",
                "    cap.release()\n",
                "\n",
                "    keypoints_sequence = np.array(keypoints_sequence)\n",
                "    if keypoints_sequence.shape != (113, 75, 3):\n",
                "      print(\"abort mission, wrong shape\")\n",
                "      return None\n",
                "\n",
                "    return keypoints_sequence # Shape: (num_frames, total_keypoints, 3)"
            ],
            "metadata": {
                "id": "S0Cj9GwDyWyn",
                "executionInfo": {
                    "status": "ok",
                    "timestamp": 1733487683686,
                    "user_tz": -420,
                    "elapsed": 283,
                    "user": {
                        "displayName": "Kenji Surya Utama",
                        "userId": "07896803662774016361"
                    }
                }
            },
            "execution_count": 4,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "DATA_DIR = '/content/drive/MyDrive/Omdena/sign_language_recognition/enhanced_videos_v2'\n",
                "SAVE_DIR = '/content/drive/MyDrive/Omdena/sign_language_recognition/landmark_non_zero'\n",
                "\n",
                "os.makedirs(SAVE_DIR, exist_ok=True)\n",
                "\n",
                "for word in os.listdir(DATA_DIR):\n",
                "    word_dir = os.path.join(DATA_DIR, word)\n",
                "    save_word_dir = os.path.join(SAVE_DIR, word)\n",
                "\n",
                "    os.makedirs(save_word_dir, exist_ok=True)\n",
                "    print(\"Processing\" , word, \"folder\")\n",
                "    for video_file in os.listdir(word_dir):\n",
                "        save_path = os.path.join(save_word_dir, video_file.replace('.mp4', '.npy'))\n",
                "\n",
                "        #Skip if the keypoints file already exists\n",
                "        if os.path.exists(save_path) and os.path.exists(save_path_zero):\n",
                "            continue\n",
                "\n",
                "        video_path = os.path.join(word_dir, video_file)\n",
                "        keypoints = extract_keypoints(video_path)\n",
                "        np.save(save_path, keypoints)  # Save as .npy"
            ],
            "metadata": {
                "id": "d0CIRajiyjYM",
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 1000
                },
                "executionInfo": {
                    "status": "error",
                    "timestamp": 1733487715461,
                    "user_tz": -420,
                    "elapsed": 10158,
                    "user": {
                        "displayName": "Kenji Surya Utama",
                        "userId": "07896803662774016361"
                    }
                },
                "outputId": "29764931-1865-41a2-aea4-f9ba04e8ccd0"
            },
            "execution_count": 5,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Processing maaf folder\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "ERROR:root:Internal Python error in the inspect module.\n",
                        "Below is the traceback from this internal error.\n",
                        "\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
                        "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
                        "  File \"<ipython-input-5-9f7c64298248>\", line 20, in <cell line: 6>\n",
                        "    keypoints = extract_keypoints(video_path)\n",
                        "  File \"<ipython-input-4-d983e3156b19>\", line 21, in extract_keypoints\n",
                        "    results = holistic.process(frame_rgb)\n",
                        "  File \"/usr/local/lib/python3.10/dist-packages/mediapipe/python/solutions/holistic.py\", line 160, in process\n",
                        "    results = super().process(input_data={'image': image})\n",
                        "  File \"/usr/local/lib/python3.10/dist-packages/mediapipe/python/solution_base.py\", line 340, in process\n",
                        "    self._graph.wait_until_idle()\n",
                        "KeyboardInterrupt\n",
                        "\n",
                        "During handling of the above exception, another exception occurred:\n",
                        "\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
                        "    stb = value._render_traceback_()\n",
                        "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
                        "\n",
                        "During handling of the above exception, another exception occurred:\n",
                        "\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
                        "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
                        "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
                        "    return f(*args, **kwargs)\n",
                        "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
                        "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
                        "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
                        "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
                        "  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n",
                        "    filename = getsourcefile(frame) or getfile(frame)\n",
                        "  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n",
                        "    module = getmodule(object, filename)\n",
                        "  File \"/usr/lib/python3.10/inspect.py\", line 875, in getmodule\n",
                        "    f = getabsfile(module)\n",
                        "  File \"/usr/lib/python3.10/inspect.py\", line 844, in getabsfile\n",
                        "    _filename = getsourcefile(object) or getfile(object)\n",
                        "  File \"/usr/lib/python3.10/inspect.py\", line 826, in getsourcefile\n",
                        "    if os.path.exists(filename):\n",
                        "  File \"/usr/lib/python3.10/genericpath.py\", line 19, in exists\n",
                        "    os.stat(path)\n",
                        "KeyboardInterrupt\n"
                    ]
                },
                {
                    "output_type": "error",
                    "ename": "TypeError",
                    "evalue": "object of type 'NoneType' has no len()",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                        "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
                        "\u001b[0;32m<ipython-input-5-9f7c64298248>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mvideo_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mkeypoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_keypoints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeypoints\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Save as .npy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m<ipython-input-4-d983e3156b19>\u001b[0m in \u001b[0;36mextract_keypoints\u001b[0;34m(video_path)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mframe_rgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mholistic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_rgb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mediapipe/python/solutions/holistic.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpose_landmarks\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pytype: disable=attribute-error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mediapipe/python/solution_base.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_until_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m     \u001b[0;31m# Create a NamedTuple object where the field names are mapping to the graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
                        "\nDuring handling of the above exception, another exception occurred:\n",
                        "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
                        "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2099\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
                        "\nDuring handling of the above exception, another exception occurred:\n",
                        "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
                        "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
                        "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2099\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2101\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2102\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
                        "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
                    ]
                }
            ]
        },
        {
            "cell_type": "markdown",
            "source": [
                "Note: It takes 46 mins for full run"
            ],
            "metadata": {
                "id": "7mZJOuWV_Rkl"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "Anything below has not been tested or run yet; it's just for future improvement or potential needs."
            ],
            "metadata": {
                "id": "gBOD6GvsEI-e"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Push to Dagshub\n",
                "\n"
            ],
            "metadata": {
                "id": "xvGFDKCtuSBN"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Install the DagsHub python client\n",
                "!pip install -q dagshub\n",
                "\n",
                "from dagshub.notebook import save_notebook\n",
                "\n",
                "save_notebook(repo=\"Omdena/JakartaIndonesia_SignLanguageTranslation\", path=\"preprocessing\", branch=\"kenji\")"
            ],
            "metadata": {
                "id": "UtPZKsiBVVkp",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "outputId": "cf1198ba-9956-420f-ecc3-f6b2b655b267"
            },
            "execution_count": null,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m252.2/252.2 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m92.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m203.2/203.2 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m74.0/74.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25h"
                    ]
                }
            ]
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Landmark Level Augmentation\n"
            ],
            "metadata": {
                "id": "c0asd4J-Dy9H"
            }
        },
        {
            "cell_type": "code",
            "source": [],
            "metadata": {
                "id": "kohu4AyfDxlj"
            },
            "execution_count": null,
            "outputs": []
        }
    ]
}