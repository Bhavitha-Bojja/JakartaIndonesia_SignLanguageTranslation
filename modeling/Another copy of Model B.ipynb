{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [
                {
                    "file_id": "1SRuLU74SAlrSXg6qou46oo5oovZ00p4o",
                    "timestamp": 1734308029103
                },
                {
                    "file_id": "1IUo8NFrz_d5KMZXMcWseocAIUBSUG7W1",
                    "timestamp": 1734269379379
                }
            ],
            "toc_visible": true
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "language_info": {
            "name": "python"
        }
    },
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# Numpy Data Prep\n",
                "if you don't want to export the npy, you can use the \"merged_data\""
            ],
            "metadata": {
                "id": "PgbI1Odf49P1"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "import os\n",
                "\n",
                "def merge_npy_files(parent_folder, output_folder, output_file_name):\n",
                "    # Initialize a list for merged data\n",
                "    merged_data = []\n",
                "\n",
                "    # Iterate through each label folder in the parent folder\n",
                "    for label in os.listdir(parent_folder):\n",
                "        label_folder = os.path.join(parent_folder, label)\n",
                "\n",
                "        # Check if it's a folder\n",
                "        if os.path.isdir(label_folder):\n",
                "            # Iterate through each npy file in the label folder\n",
                "            for file in os.listdir(label_folder):\n",
                "                if file.endswith('.npy'):\n",
                "                    file_path = os.path.join(label_folder, file)\n",
                "                    data = np.load(file_path)  # Load the npy file\n",
                "                    # Append a dictionary of data and label\n",
                "                    merged_data.append({'data': data, 'label': label, 'file_name':file})\n",
                "\n",
                "    # Save the merged data\n",
                "    os.makedirs(output_folder, exist_ok=True)  # Create the folder if it doesn't exist\n",
                "\n",
                "    np.save(os.path.join(output_folder, output_file_name), merged_data)\n",
                "\n",
                "    print(\"Merged data saved successfully!\")"
            ],
            "metadata": {
                "id": "l-FDVMp245_x"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "parent_folder = '/content/drive/MyDrive/Omdena/sign_language_recognition/train'\n",
                "output_folder = '/content/drive/MyDrive/Omdena/sign_language_recognition'\n",
                "output_file_name = 'train.npy'\n",
                "merge_npy_files(parent_folder, output_folder, output_file_name)"
            ],
            "metadata": {
                "id": "eTdKVL8T5M0k"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "parent_folder = '/content/drive/MyDrive/Omdena/sign_language_recognition/test'\n",
                "output_folder = '/content/drive/MyDrive/Omdena/sign_language_recognition'\n",
                "output_file_name = 'test.npy'\n",
                "merge_npy_files(parent_folder, output_folder, output_file_name)"
            ],
            "metadata": {
                "id": "Gt6nrsc75She"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Start Here"
            ],
            "metadata": {
                "id": "vznhN1l-47V8"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Data Preprocessing"
            ],
            "metadata": {
                "id": "FljaJVPwzNr0"
            }
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "3Z_mqin20Z0W"
            },
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "\n",
                "from sklearn.preprocessing import LabelEncoder\n",
                "\n",
                "import tensorflow as tf\n",
                "from tensorflow.keras import layers, models\n",
                "\n",
                "from tensorflow.keras.callbacks import Callback\n",
                "from tensorflow.keras.optimizers import AdamW"
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "train_data = np.load('/content/drive/MyDrive/train.npy', allow_pickle=True)\n",
                "X_train = [item['data'] for item in train_data]\n",
                "y_train = [item['label'] for item in train_data]\n",
                "\n",
                "# # Convert to NumPy arrays\n",
                "X_train = np.array(X_train)\n",
                "y_train = np.array(y_train)\n",
                "\n",
                "test_data = np.load('/content/drive/MyDrive/test.npy', allow_pickle=True)\n",
                "# Extract features (X) and labels (y)\n",
                "X_test = [item['data'] for item in test_data]\n",
                "y_test = [item['label'] for item in test_data]\n",
                "\n",
                "# Convert to NumPy arrays\n",
                "X_test = np.array(X_test)\n",
                "y_test = np.array(y_test)"
            ],
            "metadata": {
                "id": "hCsfns5o0jiR"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Create a LabelEncoder instance\n",
                "label_encoder = LabelEncoder()\n",
                "\n",
                "# Fit and transform the labels\n",
                "y_train = label_encoder.fit_transform(y_train)\n",
                "y_test = label_encoder.transform(y_test)"
            ],
            "metadata": {
                "id": "fJLMxH0z0pBj"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "def smooth_labels(y_true, num_classes, smoothing=0.1):\n",
                "    # Convert to one-hot\n",
                "    y_true_one_hot = tf.one_hot(y_true, depth=num_classes)\n",
                "    # Apply smoothing\n",
                "    smoothed_labels = y_true_one_hot * (1 - smoothing) + (smoothing / num_classes)\n",
                "    return smoothed_labels\n",
                "\n",
                "# Usage in loss function\n",
                "num_classes = 30\n",
                "label_smoothing = 0.1\n",
                "y_train_smoothed = smooth_labels(y_train, num_classes, smoothing=label_smoothing)\n",
                "y_test_smoothed = smooth_labels(y_test, num_classes, smoothing=label_smoothing)"
            ],
            "metadata": {
                "id": "hp1YoGWb2Bv5"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "def calculate_angle(A, B, C):\n",
                "    BA = A - B\n",
                "    BC = C - B\n",
                "    # Compute dot product and magnitudes\n",
                "    dot_product = np.dot(BA, BC)\n",
                "    magnitude_BA = np.linalg.norm(BA)\n",
                "    magnitude_BC = np.linalg.norm(BC)\n",
                "    # Prevent division by zero\n",
                "    if magnitude_BA == 0 or magnitude_BC == 0:\n",
                "        return 0.0\n",
                "    # Calculate the cosine of the angle\n",
                "    cos_angle = dot_product / (magnitude_BA * magnitude_BC)\n",
                "    # Clip values to handle numerical errors\n",
                "    cos_angle = np.clip(cos_angle, -1.0, 1.0)\n",
                "    # Return the angle in radians\n",
                "    return np.arccos(cos_angle)"
            ],
            "metadata": {
                "id": "-MTGXkf609hS"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "def get_angles(X):\n",
                "    # Reshape the data into (n_videos, n_frames, n_keypoints, 3)\n",
                "    n_videos, n_frames, n_features = X.shape\n",
                "    n_keypoints = 75\n",
                "    X_reshaped = X.reshape(n_videos, n_frames, n_keypoints, 3)\n",
                "\n",
                "    # Define keypoints for angle calculation (indices start from 0)\n",
                "    pose_angle_indices = [\n",
                "        (12, 14, 16),\n",
                "        (14, 16, 18),\n",
                "        (18, 16, 22),\n",
                "        (14, 12, 24),\n",
                "\n",
                "        (11, 13, 15),\n",
                "        (13, 15, 17),\n",
                "        (17, 15, 21),\n",
                "        (13, 11, 23),\n",
                "    ]\n",
                "    # For both left and right hands\n",
                "    hand_angle_indices = [(4, 0, 8),\n",
                "                          (8, 0, 16),\n",
                "                          (0, 9, 12),\n",
                "                          (0, 17,20),\n",
                "                          ]\n",
                "\n",
                "    # Calculate angles for each video and frame\n",
                "    angles_list = []\n",
                "    for video in X_reshaped:\n",
                "        video_angles = []\n",
                "        for frame in video:\n",
                "            frame_angles = []\n",
                "            # Pose angles\n",
                "            for (i, j, k) in pose_angle_indices:\n",
                "                frame_angles.append(calculate_angle(frame[i], frame[j], frame[k]))\n",
                "            # Left hand angles\n",
                "            for (i, j, k) in hand_angle_indices:\n",
                "                frame_angles.append(calculate_angle(frame[33 + i], frame[33 + j], frame[33 + k]))\n",
                "            # Right hand angles\n",
                "            for (i, j, k) in hand_angle_indices:\n",
                "                frame_angles.append(calculate_angle(frame[54 + i], frame[54 + j], frame[54 + k]))\n",
                "            video_angles.append(frame_angles)\n",
                "        angles_list.append(video_angles)\n",
                "\n",
                "    # Convert angles list to a numpy array\n",
                "    angles_array = np.array(angles_list)  # Shape: (n_videos, n_frames, n_angles)\n",
                "    return angles_array"
            ],
            "metadata": {
                "id": "rJ2TO7za0_8m"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Get joint angles\n",
                "X_train_angles = get_angles(X_train)\n",
                "X_test_angles = get_angles(X_test)\n",
                "\n",
                "# Compute mean and standard deviation of the training data\n",
                "mean = X_train.mean(axis=0)\n",
                "std = X_train.std(axis=0)\n",
                "\n",
                "# Flatten the data\n",
                "X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
                "X_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
                "\n",
                "# Create normalization layer\n",
                "normalization_layer = layers.Normalization(axis=-1)\n",
                "\n",
                "# Adapt the layer to the flattened training data\n",
                "normalization_layer.adapt(X_train_flat)\n",
                "\n",
                "# Standardize the flattened data\n",
                "X_train_standardized_flat = normalization_layer(X_train_flat).numpy()\n",
                "X_test_standardized_flat = normalization_layer(X_test_flat).numpy()\n",
                "\n",
                "# Reshape back to original\n",
                "X_train_standardized = X_train_standardized_flat.reshape(X_train.shape)\n",
                "X_test_standardized = X_test_standardized_flat.reshape(X_test.shape)\n",
                "\n",
                "# Add angles to standardized X\n",
                "X_train = np.concatenate([X_train_standardized, X_train_angles],axis=-1)\n",
                "X_test = np.concatenate([X_test_standardized, X_test_angles],axis=-1)\n",
                "\n",
                "# Convert to TensorFlow format\n",
                "X_train = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
                "X_test = tf.convert_to_tensor(X_test, dtype=tf.float32)\n",
                "y_train = tf.convert_to_tensor(y_train_smoothed, dtype=tf.float32)\n",
                "y_test = tf.convert_to_tensor(y_test_smoothed, dtype=tf.float32)"
            ],
            "metadata": {
                "id": "qMr6Zc-F1AiK"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Modeling"
            ],
            "metadata": {
                "id": "tAzicUYnzSsM"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "def create_transformer_model(input_shape, num_classes):\n",
                "    inputs = layers.Input(shape=input_shape)\n",
                "\n",
                "    # Positional Encoding\n",
                "    positional_encoding = layers.Embedding(input_dim=input_shape[0], output_dim=input_shape[1])(tf.range(input_shape[0]))\n",
                "    x = inputs + positional_encoding\n",
                "\n",
                "    # Transformer Encoder\n",
                "    for _ in range(4):  # Number of Transformer blocks\n",
                "        # Normalized before attention, instead of after\n",
                "        x_norm = layers.LayerNormalization(epsilon=1e-6)(x)\n",
                "        # Instead of 4 (base), 8 used. Increase key dimensions into 128 from 64\n",
                "        attention_output = layers.MultiHeadAttention(num_heads=8, key_dim=128)(x_norm, x_norm)\n",
                "        x = x + attention_output\n",
                "        # Instead of a single layer with 241 units, 1 denser layer added\n",
                "        ff_output = layers.Dense(512, activation='relu')(x)\n",
                "        ff_output = layers.Dense(241, activation='relu')(x)\n",
                "        x = layers.LayerNormalization(epsilon=1e-6)(x + ff_output)\n",
                "\n",
                "    # Global Average Pooling\n",
                "    x = layers.GlobalAveragePooling1D()(x)\n",
                "\n",
                "    # Output Layer\n",
                "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
                "\n",
                "    return models.Model(inputs, outputs)"
            ],
            "metadata": {
                "id": "PwJ0qlrO1EfT"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "input_shape = (113, 241)  # (n_frames, n_keypoints * n_coordinates + n_angles)\n",
                "num_classes = 30\n",
                "\n",
                "transformer_model = create_transformer_model(input_shape, num_classes)\n",
                "\n",
                "# Compile the model\n",
                "transformer_model.compile(\n",
                "    optimizer=AdamW(learning_rate=0.001, weight_decay=1e-4),\n",
                "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
                "    metrics=[\"accuracy\"]\n",
                ")\n",
                "\n",
                "# Add the learning rate scheduler callback\n",
                "lr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
                "    monitor='val_loss',\n",
                "    factor=0.5,\n",
                "    patience=3,\n",
                "    min_lr=1e-6\n",
                ")\n",
                "# Add early stopping callback\n",
                "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
                "    monitor='val_loss',\n",
                "    patience=5,\n",
                "    restore_best_weights=True\n",
                ")\n",
                "# Combine Callbacks\n",
                "callbacks = [lr_callback, early_stopping]\n",
                "\n",
                "model = transformer_model.fit(\n",
                "    X_train, y_train,\n",
                "    validation_data=(X_test, y_test),\n",
                "    epochs=50,\n",
                "    batch_size=32,\n",
                "    callbacks=[callbacks]\n",
                ")"
            ],
            "metadata": {
                "id": "w8VNlwu1wR8M",
                "executionInfo": {
                    "status": "ok",
                    "timestamp": 1734307105692,
                    "user_tz": -420,
                    "elapsed": 73525,
                    "user": {
                        "displayName": "kenji surya utama",
                        "userId": "07400952506554819917"
                    }
                },
                "outputId": "4bd1d21d-e414-47c7-ea4d-af2797352957",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                }
            },
            "execution_count": null,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Epoch 1/50\n",
                        "\u001b[1m38/38\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 330ms/step - accuracy: 0.2483 - loss: 3.0896 - val_accuracy: 0.3500 - val_loss: 2.3286 - learning_rate: 0.0010\n",
                        "Epoch 2/50\n",
                        "\u001b[1m38/38\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.6456 - loss: 1.6634 - val_accuracy: 0.4500 - val_loss: 2.2198 - learning_rate: 0.0010\n",
                        "Epoch 3/50\n",
                        "\u001b[1m38/38\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.7107 - loss: 1.4490 - val_accuracy: 0.6167 - val_loss: 1.7128 - learning_rate: 0.0010\n",
                        "Epoch 4/50\n",
                        "\u001b[1m38/38\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.8864 - loss: 1.0153 - val_accuracy: 0.7167 - val_loss: 1.5058 - learning_rate: 0.0010\n",
                        "Epoch 5/50\n",
                        "\u001b[1m38/38\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.9589 - loss: 0.8389 - val_accuracy: 0.7667 - val_loss: 1.3992 - learning_rate: 0.0010\n",
                        "Epoch 6/50\n",
                        "\u001b[1m38/38\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.9912 - loss: 0.7339 - val_accuracy: 0.8333 - val_loss: 1.2129 - learning_rate: 0.0010\n",
                        "Epoch 7/50\n",
                        "\u001b[1m38/38\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.6776 - val_accuracy: 0.8333 - val_loss: 1.1954 - learning_rate: 0.0010\n",
                        "Epoch 8/50\n",
                        "\u001b[1m38/38\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.6653 - val_accuracy: 0.8500 - val_loss: 1.1972 - learning_rate: 0.0010\n",
                        "Epoch 9/50\n",
                        "\u001b[1m38/38\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.6590 - val_accuracy: 0.8333 - val_loss: 1.1864 - learning_rate: 0.0010\n",
                        "Epoch 10/50\n",
                        "\u001b[1m38/38\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.6565 - val_accuracy: 0.8500 - val_loss: 1.1786 - learning_rate: 0.0010\n",
                        "Epoch 11/50\n",
                        "\u001b[1m38/38\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.6532 - val_accuracy: 0.8333 - val_loss: 1.1897 - learning_rate: 0.0010\n",
                        "Epoch 12/50\n",
                        "\u001b[1m38/38\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.6524 - val_accuracy: 0.8500 - val_loss: 1.1793 - learning_rate: 0.0010\n",
                        "Epoch 13/50\n",
                        "\u001b[1m38/38\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.6512 - val_accuracy: 0.8167 - val_loss: 1.1781 - learning_rate: 0.0010\n",
                        "Epoch 14/50\n",
                        "\u001b[1m38/38\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.6503 - val_accuracy: 0.8333 - val_loss: 1.1772 - learning_rate: 0.0010\n",
                        "Epoch 15/50\n",
                        "\u001b[1m38/38\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.9982 - loss: 0.6629 - val_accuracy: 0.7667 - val_loss: 1.3822 - learning_rate: 0.0010\n",
                        "Epoch 16/50\n",
                        "\u001b[1m38/38\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.9794 - loss: 0.7319 - val_accuracy: 0.6333 - val_loss: 1.9853 - learning_rate: 0.0010\n",
                        "Epoch 17/50\n",
                        "\u001b[1m38/38\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.8531 - loss: 1.1241 - val_accuracy: 0.3167 - val_loss: 3.1306 - learning_rate: 0.0010\n",
                        "Epoch 18/50\n",
                        "\u001b[1m38/38\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.6972 - loss: 1.6076 - val_accuracy: 0.6500 - val_loss: 1.6754 - learning_rate: 5.0000e-04\n",
                        "Epoch 19/50\n",
                        "\u001b[1m38/38\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9915 - loss: 0.7921 - val_accuracy: 0.7667 - val_loss: 1.3812 - learning_rate: 5.0000e-04\n"
                    ]
                }
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "# Get the epoch with the best performance\n",
                "best_epoch = early_stopping.stopped_epoch - early_stopping.patience + 1\n",
                "\n",
                "# Print the metrics of the best epoch\n",
                "best_val_loss = model.history['val_loss'][best_epoch - 1]\n",
                "best_val_accuracy = model.history['val_accuracy'][best_epoch - 1]  # Change to the metric you're tracking\n",
                "\n",
                "print(f\"Best Epoch: {best_epoch}\")\n",
                "print(f\"Validation Loss: {best_val_loss}\")\n",
                "print(f\"Validation Accuracy: {best_val_accuracy}\")"
            ],
            "metadata": {
                "id": "jw7Ob5AYxFz-",
                "executionInfo": {
                    "status": "ok",
                    "timestamp": 1734307283733,
                    "user_tz": -420,
                    "elapsed": 514,
                    "user": {
                        "displayName": "kenji surya utama",
                        "userId": "07400952506554819917"
                    }
                },
                "outputId": "e3a39d37-17d9-4ed6-c892-1246ebdc7468",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                }
            },
            "execution_count": null,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Best Epoch: 14\n",
                        "Validation Loss: 1.1771689653396606\n",
                        "Validation Accuracy: 0.8333333134651184\n"
                    ]
                }
            ]
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Save the model"
            ],
            "metadata": {
                "id": "kcmwtLhSuuVV"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Save the trained model as TensorFlow SavedModel\n",
                "transformer_model.save('/content/drive/MyDrive/transformer_model_b.keras')"
            ],
            "metadata": {
                "id": "cw23J5evud81"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Sanity check, whether it saved the best weight\n",
                "loaded_model = tf.keras.models.load_model('/content/drive/MyDrive/transformer_model_b.keras')\n",
                "\n",
                "# Evaluate on validation data\n",
                "val_loss, val_accuracy = loaded_model.evaluate(X_test, y_test)\n",
                "\n",
                "print(f\"Validation Loss: {val_loss}\")\n",
                "print(f\"Validation Accuracy: {val_accuracy}\")"
            ],
            "metadata": {
                "id": "Khb4GlVfvCeb",
                "executionInfo": {
                    "status": "ok",
                    "timestamp": 1734307498156,
                    "user_tz": -420,
                    "elapsed": 6759,
                    "user": {
                        "displayName": "kenji surya utama",
                        "userId": "07400952506554819917"
                    }
                },
                "outputId": "974b91dd-3c14-4d83-e5b3-bbfabccdfbae",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                }
            },
            "execution_count": null,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\u001b[1m2/2\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2s/step - accuracy: 0.8368 - loss: 1.1773\n",
                        "Validation Loss: 1.1771689653396606\n",
                        "Validation Accuracy: 0.8333333134651184\n"
                    ]
                }
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "!pip install -q dagshub\n",
                "\n",
                "from dagshub.notebook import save_notebook\n",
                "\n",
                "save_notebook(repo=\"Omdena/JakartaIndonesia_SignLanguageTranslation\", path=\"modeling\", branch=\"kenji\", commit_message=\"Current Final Model\")"
            ],
            "metadata": {
                "id": "HgcQNKrhovno"
            },
            "execution_count": null,
            "outputs": []
        }
    ]
}